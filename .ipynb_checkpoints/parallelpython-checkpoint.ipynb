{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Add all necessary imports here\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.reload_library()\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<image>\n",
    "<section>\n",
    "<div>\n",
    "    <div>\n",
    "        <p> &nbsp;</p>\n",
    "        <h1>Parallel computing in <strong>Python</strong> </h1>\n",
    "         <p>\n",
    "             <strong><span>Vamshidhar Gangu</span></strong>\n",
    "         </p>\n",
    "         <p>\n",
    "             <span> HPC specialist</span> \n",
    "         </p>\n",
    "         <p>&nbsp;</p>\n",
    "         <p>&nbsp;</p>\n",
    "</div>\n",
    "</section>\n",
    "</image>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python GIL\n",
    " \n",
    "* Global Interpreter Lock\n",
    "* default Python is designed with simplicity in mind, so they made it thread-safe (GIL)\n",
    "* Restrict python to run in a single thread\n",
    "* __exectues only one statement at a time (serial processing or single-threading)__\n",
    "* Cannot make use of data stored in shared memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "\n",
    "![pGIL](img/pGIL.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Python GIL problem\n",
    "\n",
    "_**Factorial example using Threading**_\n",
    "\n",
    "``` python\n",
    "from datetime import datetime\n",
    "import threading \n",
    "\n",
    "def factorial(number): \n",
    "    fact = 1\n",
    "    for n in range(1, number+1): \n",
    "        fact *= n \n",
    "    return fact \n",
    "\n",
    "number = 100000 \n",
    "thread = threading.Thread(target=factorial, args=(number,)) \n",
    "startTime = datetime.now() \n",
    "thread.start() \n",
    "thread.join() \n",
    "endTime = datetime.now() \n",
    "print \"Time for execution: \", endTime - startTime\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "run time:\n",
    "    * 1 Thread  : 3.4 sec\n",
    "    * 2 Threads : 6.2 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- You donâ€™t get the concurrency needed with Python multithreading because of the Global interpreter lock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-threading vs. multi-processing\n",
    "\n",
    "### multi-threading\n",
    "* jobs pictured as \"sub-tasks\" of a single process \n",
    "* have access to the same memory (shared memory)\n",
    "* can lead conflicts (improper synchronization) \n",
    "    * _writing to same memory location at the same time_\n",
    "\n",
    "### multi-processing\n",
    "* safer approach (although has communication overhead)\n",
    "* each process is completed independently from each other\n",
    "\n",
    "![parallel-serial](img/thread-process.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Map function\n",
    "\n",
    "Used to run a function over multiple elements\n",
    "\n",
    "``` python\n",
    "def square(a):\n",
    "    return a*a\n",
    "    \n",
    "outputs =[]\n",
    "for i in inputs:\n",
    "    outpus.append(square(i))\n",
    "\n",
    "# or\n",
    "outputs = [square(i) for i in inputs]\n",
    "\n",
    "#or\n",
    "\n",
    "outputs = map(f, inputs)\n",
    "```\n",
    "\n",
    "\n",
    "![mapfn](img/map_fn.PNG)\n",
    "\n",
    "### Implemented by _many_ frameworks\n",
    "`concurrent.futures, multiprocessing, joblib, dask, ipyparallel, spark`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parallel frameworks \n",
    "\n",
    "\n",
    "- [multiprocessing](https://docs.python.org/2/library/multiprocessing.html)\n",
    "\n",
    "- [__*concurrent.futures*__](https://docs.python.org/3/library/concurrent.futures.html)\n",
    "\n",
    "- [__*joblib*__](https://pythonhosted.org/joblib/)\n",
    "\n",
    "- [ipyparallel](https://ipyparallel.readthedocs.io/en/latest/)\n",
    "\n",
    "- [__*MPI4py*__](http://mpi4py.readthedocs.io/en/stable/)\n",
    "\n",
    "- [Dask](https://dask.pydata.org/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# futures (concurrent.futures)\n",
    "* part of standard library (python 3.2)\n",
    "* abstract layer on top of Python's threading and multiprocessing modules\n",
    "\n",
    "* **`executor`**\n",
    "    * abstract class (can not be used directly)\n",
    "    * *`ThreadPoolExecutor`* :- multithreading\n",
    "    * *`ProcessPoolExecutor`* :- multiprocessing\n",
    "    * submit multiple tasks to `Pool`\n",
    "    * `Pool` assign tasks and schedule them to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# futures: sum of all primes below *n*\n",
    "\n",
    "``` python\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "def is_prime(num):\n",
    "    if num <= 1:\n",
    "        return False\n",
    "    elif num <= 3:\n",
    "        return True\n",
    "    elif num%2 == 0 or num%3 == 0:\n",
    "        return False\n",
    "    i = 5\n",
    "    while i*i <= num:\n",
    "        if num%i == 0 or num%(i+2) == 0:\n",
    "            return False\n",
    "        i += 6\n",
    "    return True\n",
    "\n",
    "\n",
    "def find_sum(num):\n",
    "    sum_of_primes = 0\n",
    "    ix = 2\n",
    "    while ix <= num:\n",
    "        if is_prime(ix):\n",
    "            sum_of_primes += ix\n",
    "        ix += 1\n",
    "    return sum_of_primes\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### multi threading\n",
    "``` python\n",
    "def sum_primes_thread(nums):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers = 4) as executor:\n",
    "        for number, sum_res in zip(nums, executor.map(find_sum, nums)):\n",
    "            print(\"{} : Sum = {}\".format(number, sum_res))\n",
    "```\n",
    "### multiprocessing\n",
    "``` python\n",
    "def sum_primes_process(nums):\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers = 4) as executor:\n",
    "        for number, sum_res in zip(nums, executor.map(find_sum, nums)):\n",
    "            print(\"{} : Sum = {}\".format(number, sum_res))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    nums = [100000, 200000, 300000]\n",
    "    start = time.time()\n",
    "    sum_primes_thread(nums)\n",
    "    print(\"Time taken = {0:.5f}\".format(time.time() - start))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Output when executing `sum_primes_thread`\n",
    "\n",
    "`\n",
    "100000 : Sum = 454396537\n",
    "200000 : Sum = 1709600813\n",
    "300000 : Sum = 3709507114\n",
    "Time Taken = 0.71783\n",
    "`\n",
    "\n",
    "Output when executing `sum_primes_thread`\n",
    "\n",
    "`\n",
    "100000 : Sum = 454396537\n",
    "200000 : Sum = 1709600813\n",
    "300000 : Sum = 3709507114\n",
    "Time Taken = 1.2338\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## as_completed() & wait()\n",
    "\n",
    "#### as_completed\n",
    "* yeilds results as soon as futures start resolving\n",
    "* vs `map()` : returns the results in order\n",
    "\n",
    "#### wait()\n",
    "* returns tuple with two sets\n",
    "* one with completed and other conatins the uncompleted one's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "``` python\n",
    "from concurrent.futures import ThreadPoolExecutor, wait, as_completed\n",
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "def return_after_5_secs(num):\n",
    "    sleep(randint(1, 5))\n",
    "    return \"Return of {}\".format(num)\n",
    "\n",
    "pool = ThreadPoolExecutor(5)\n",
    "futures = []\n",
    "for x in range(5):\n",
    "    futures.append(pool.submit(return_after_5_secs, x))\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*`as_completed`*\n",
    "\n",
    "``` python\n",
    "for x in as_completed(futures):\n",
    "    print(x.result())\n",
    "```\n",
    "\n",
    "_`wait`_\n",
    "``` python\n",
    "print(wait(futures))\n",
    "```\n",
    "* `wait` controls : `return_when` : `FIRST_COMPLETED, FIRST_EXCEPTION`, `ALL_COMPLETED`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# joblib\n",
    "* another parallel processing library\n",
    "* developed by authors who work on *scikit-learn*\n",
    "* also built on top of multiprocessing, multithreading\n",
    "* ability to use a pool of worker like a context manager, reused across several tasks to be parallized\n",
    "* if `njobs` set to 1, then it is puerly sequential mode, no overhead of setting up a pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-256e021a3919>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'joblib'"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from math import sqrt\n",
    "Parallel(n_jobs=1)(delayed(sqrt) (i**2) for i in range(10))\n",
    "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MPI4py\n",
    "\n",
    "* python binding for MPI (Message Passing Interface)\n",
    "* _distributed_ parallel programming in python\n",
    "* Based ob MPI-2 C++ bindings\n",
    "* Almost all MPI calls supported\n",
    "* API docs: http://pythonhosted.org/mpi4py/apiref/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " **multi-process**, not multi-thread\n",
    " \n",
    " **multi-node**, not multi-core\n",
    " \n",
    " **message-passing**, not shared memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* http://sebastianraschka.com/Articles/2014_multiprocessing.html\n",
    "* http://masnun.com/2016/03/29/python-a-quick-introduction-to-the-concurrent-futures-module.html\n",
    "* http://pydata.github.io"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
